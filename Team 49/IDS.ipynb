!wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names
!wget http://kdd.ics.uci.edu/databases/kddcup99/training_attack_types
!wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time
import gzip
import shutil

with open('kddcup.names', 'r') as f:
    print(f.read())

cols ="""duration,
protocol_type,
service,
flag,
src_bytes,
dst_bytes,
land,
wrong_fragment,
urgent,
hot,
num_failed_logins,
logged_in,
num_compromised,
root_shell,
su_attempted,
num_root,
num_file_creations,
num_shells,
num_access_files,
num_outbound_cmds,
is_host_login,
is_guest_login,
count,
srv_count,
serror_rate,
srv_serror_rate,
rerror_rate,
srv_rerror_rate,
same_srv_rate,
diff_srv_rate,
srv_diff_host_rate,
dst_host_count,
dst_host_srv_count,
dst_host_same_srv_rate,
dst_host_diff_srv_rate,
dst_host_same_src_port_rate,
dst_host_srv_diff_host_rate,
dst_host_serror_rate,
dst_host_srv_serror_rate,
dst_host_rerror_rate,
dst_host_srv_rerror_rate"""

columns =[]
for c in cols.split(',\n'):
    if(c.strip()):
       columns.append(c.strip())

columns.append('target')
print(len(columns))

with open('training_attack_types', 'r') as f:
    print(f.read())

attacks_types = {
    'normal': 'normal',
'back': 'dos',
'buffer_overflow': 'u2r',
'ftp_write': 'r2l',
'guess_passwd': 'r2l',
'imap': 'r2l',
'ipsweep': 'probe',
'land': 'dos',
'loadmodule': 'u2r',
'multihop': 'r2l',
'neptune': 'dos',
'nmap': 'probe',
'perl': 'u2r',
'phf': 'r2l',
'pod': 'dos',
'portsweep': 'probe',
'rootkit': 'u2r',
'satan': 'probe',
'smurf': 'dos',
'spy': 'r2l',
'teardrop': 'dos',
'warezclient': 'r2l',
'warezmaster': 'r2l',
}

input_file = 'kddcup.data_10_percent.gz'
output_file = 'kddcup.data'

# Extract the file
with gzip.open(input_file, 'rb') as f_in:
    with open(output_file, 'wb') as f_out:
        shutil.copyfileobj(f_in, f_out)

print(f"File extracted to: {output_file}")

df = pd.read_csv(output_file, names = columns)
df['Attack Type'] = df.target.apply(lambda r:attacks_types[r[:-1]])
df.head()
df.isnull().sum()

num_cols = df._get_numeric_data().columns # numerical data in columns
cate_cols = list(set(df.columns)-set(num_cols))
cate_cols.remove('target')
cate_cols.remove('Attack Type')

df = df.dropna(axis='columns')

ndf = df[[col for col in df.columns if df[col].nunique() > 1 and pd.api.types.is_numeric_dtype(df[col])]]
corr = ndf.corr()

plt.figure(figsize =(15, 12))
sns.heatmap(corr)
plt.show()

#From the heatmap, you can identify pairs of features with correlations above a threshold (e.g., 0.9) and drop one of each pair.

df.drop('num_root', axis = 1, inplace = True)
df.drop('srv_serror_rate', axis = 1, inplace = True)
df.drop('srv_rerror_rate', axis = 1, inplace = True)
df.drop('dst_host_srv_serror_rate', axis = 1, inplace =True)
df.drop('dst_host_serror_rate', axis = 1, inplace =True)
df.drop('dst_host_rerror_rate', axis = 1, inplace =True)
df.drop('dst_host_srv_rerror_rate', axis = 1, inplace =True)
df.drop('dst_host_same_srv_rate', axis = 1, inplace =True)
df.drop('service', axis = 1, inplace = True) # not needed for model training

# protocol_type feature mapping
pmap = {'icmp':0, 'tcp':1, 'udp':2}
df['protocol_type'] = df['protocol_type'].map(pmap)
# flag feature mapping
fmap = {'SF':0, 'S0':1, 'REJ':2, 'RSTR':3, 'RSTO':4, 'SH':5, 'S1':6, 'S2':7, 'RSTOS0':8, 'S3':9, 'OTH':10}
df['flag'] = df['flag'].map(fmap)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
df = df.drop(['target', ], axis = 1)
print(df.shape)

# Target variable and train set
y = df[['Attack Type']]
X = df.drop(['Attack Type', ], axis = 1)
sc = MinMaxScaler()           #The MinMaxScaler() is a preprocessing tool from sklearn.preprocessing. It scales each feature to a given range, typically [0, 1] by default.
X = sc.fit_transform(X)

# Split test and train data
from imblearn.over_sampling import SMOTE
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)
print( X_train.shape, y_train.shape)

# Gausian Naive Bayes
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

clfg = GaussianNB()
start_time = time.time()
clfg.fit(X_train, y_train.values.ravel())
end_time = time.time()
print("Training time: ", end_time-start_time)
start_time = time.time()
y_test_pred_g = clfg.predict(X_test)
end_time = time.time()
print("Testing time: ", end_time-start_time)
print("Train score is:", clfg.score(X_train, y_train))
print("Test score is:", clfg.score(X_test, y_test))

# Decision Tree
from sklearn.tree import DecisionTreeClassifier

clfd = DecisionTreeClassifier(criterion ="entropy", max_depth = 4,class_weight='balanced')
start_time = time.time()
clfd.fit(X_train, y_train.values.ravel())
end_time = time.time()
print("Training time: ", end_time-start_time)
start_time = time.time()
y_test_pred_d = clfd.predict(X_test)
end_time = time.time()
print("Testing time: ", end_time-start_time)
print("Train score is:", clfd.score(X_train, y_train))
print("Test score is:", clfd.score(X_test, y_test))

# Random Forest
from sklearn.ensemble import RandomForestClassifier

clfr = RandomForestClassifier(n_estimators = 30,class_weight='balanced')
start_time = time.time()
clfr.fit(X_train, y_train.values.ravel())
end_time = time.time()
print("Training time: ", end_time-start_time)
start_time = time.time()
y_test_pred_r = clfr.predict(X_test)
end_time = time.time()
print("Testing time: ", end_time-start_time)
print("Train score is:", clfr.score(X_train, y_train))
print("Test score is:", clfr.score(X_test, y_test))

from sklearn.metrics import classification_report

# For each classifier
print("GaussianNB Classification Report:")
print(classification_report(y_test, y_test_pred_g))

print("DecisionTree Classification Report:")
print(classification_report(y_test, y_test_pred_d,zero_division=0))

print("RandomForest Classification Report:")
print(classification_report(y_test, y_test_pred_r))

#Comparitive graph
names = ['GNB', 'DT', 'RF']
values = [89, 93, 96]

f = plt.figure(figsize=(15, 3), num=10)
plt.subplot(131)
plt.bar(names, values, color=['skyblue', 'orange', 'green'])
plt.xlabel('Models')
plt.ylabel('Accuracy (%)')
plt.title('Model Accuracy Comparison')
plt.tight_layout()
plt.show()

from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

# Define base models
base_estimators = [
    ('gnb', clfg),
    ('dt', clfd),
    ('rf', clfr)
]
# Define the meta-model (Logistic Regression in this case)
meta_model = LogisticRegression(class_weight='balanced')
# Create the StackingClassifier
stacking_model = StackingClassifier(
    estimators=base_estimators,
    final_estimator=meta_model,
    passthrough=True  # Pass original features along with predictions to the meta-model
)
# Train the stacking model
print("Training Stacking Model...")
stacking_model.fit(X_train, y_train.values.ravel())
# Predict on test data
y_test_pred = stacking_model.predict(X_test)
# Evaluate the stacking model
print("\nStacking Model Accuracy:", accuracy_score(y_test, y_test_pred))
print("\nClassification Report for Stacking Model:\n")
print(classification_report(y_test, y_test_pred))

# Count of different types of attacks
print("Attack type distribution:")
print(df['Attack Type'].value_counts())
